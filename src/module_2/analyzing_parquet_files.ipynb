{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/groceries/sampled-datasets'\n",
    "\n",
    "parquet_files = [f for f in os.listdir(folder)]\n",
    "for f in parquet_files:\n",
    "    locals()[f'df_{f.rsplit(\".\",1)[0]}'] = pd.read_parquet(str(folder+'/'+f))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8773 entries, 10 to 64538\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id              8773 non-null   int64         \n",
      " 1   user_id         8773 non-null   object        \n",
      " 2   created_at      8773 non-null   datetime64[us]\n",
      " 3   order_date      8773 non-null   datetime64[us]\n",
      " 4   user_order_seq  8773 non-null   int64         \n",
      " 5   ordered_items   8773 non-null   object        \n",
      "dtypes: datetime64[us](2), int64(2), object(2)\n",
      "memory usage: 479.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>order_date</th>\n",
       "      <th>user_order_seq</th>\n",
       "      <th>ordered_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2204073066628</td>\n",
       "      <td>62e271062eb827e411bd73941178d29b022f5f2de9d37f...</td>\n",
       "      <td>2020-04-30 14:32:19</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>[33618849693828, 33618860179588, 3361887404045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2204707520644</td>\n",
       "      <td>bf591c887c46d5d3513142b6a855dd7ffb9cc00697f6f5...</td>\n",
       "      <td>2020-04-30 17:39:00</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>[33618835243140, 33618835964036, 3361886244058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2204838822020</td>\n",
       "      <td>329f08c66abb51f8c0b8a9526670da2d94c0c6eef06700...</td>\n",
       "      <td>2020-04-30 18:12:30</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>[33618891145348, 33618893570180, 3361889766618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2208967852164</td>\n",
       "      <td>f6451fce7b1c58d0effbe37fcb4e67b718193562766470...</td>\n",
       "      <td>2020-05-01 19:44:11</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>[33618830196868, 33618846580868, 3361891234624...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2215889436804</td>\n",
       "      <td>68e872ff888303bff58ec56a3a986f77ddebdbe5c279e7...</td>\n",
       "      <td>2020-05-03 21:56:14</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>1</td>\n",
       "      <td>[33667166699652, 33667166699652, 3366717122163...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            user_id  \\\n",
       "10  2204073066628  62e271062eb827e411bd73941178d29b022f5f2de9d37f...   \n",
       "20  2204707520644  bf591c887c46d5d3513142b6a855dd7ffb9cc00697f6f5...   \n",
       "21  2204838822020  329f08c66abb51f8c0b8a9526670da2d94c0c6eef06700...   \n",
       "34  2208967852164  f6451fce7b1c58d0effbe37fcb4e67b718193562766470...   \n",
       "49  2215889436804  68e872ff888303bff58ec56a3a986f77ddebdbe5c279e7...   \n",
       "\n",
       "            created_at order_date  user_order_seq  \\\n",
       "10 2020-04-30 14:32:19 2020-04-30               1   \n",
       "20 2020-04-30 17:39:00 2020-04-30               1   \n",
       "21 2020-04-30 18:12:30 2020-04-30               1   \n",
       "34 2020-05-01 19:44:11 2020-05-01               1   \n",
       "49 2020-05-03 21:56:14 2020-05-03               1   \n",
       "\n",
       "                                        ordered_items  \n",
       "10  [33618849693828, 33618860179588, 3361887404045...  \n",
       "20  [33618835243140, 33618835964036, 3361886244058...  \n",
       "21  [33618891145348, 33618893570180, 3361889766618...  \n",
       "34  [33618830196868, 33618846580868, 3361891234624...  \n",
       "49  [33667166699652, 33667166699652, 3366717122163...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.info()\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4983 entries, 2160 to 3360\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   user_id                4983 non-null   object \n",
      " 1   user_segment           4983 non-null   object \n",
      " 2   user_nuts1             4932 non-null   object \n",
      " 3   first_ordered_at       4983 non-null   object \n",
      " 4   customer_cohort_month  4983 non-null   object \n",
      " 5   count_people           325 non-null    float64\n",
      " 6   count_adults           325 non-null    float64\n",
      " 7   count_children         325 non-null    float64\n",
      " 8   count_babies           325 non-null    float64\n",
      " 9   count_pets             325 non-null    float64\n",
      "dtypes: float64(5), object(5)\n",
      "memory usage: 428.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values:\n",
    "  - Users: we have nulls in the ‘user_nuts1’ columns and the ‘count_people’ columns and derivatives, which are attributed to lack of information added by users. (4983,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypotheses about what we think we know:\n",
    "1. London and South East UK areas have a higher level of income, assuming this fact they should spend more than the rest of the areas. (To validate this we will use the 'user_nuts1' variable from the user dataframe).\n",
    "2. Users segmented as Top-Up should make small purchases with a high frequency and users segmented as Proposition should make large purchases infrequently. (To validate this we will use the 'user_segment' variable from the user dataframe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we would like to know:\n",
    "1. Which products sell the most by geographic area, to see if there is variation in specific products between different areas.\n",
    "2. Check if there is a relationship between product_type and cart abandonment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 1:\n",
    "The price of orders is higher in regions with higher level of income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107958 entries, 0 to 107957\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   id              107958 non-null  int64         \n",
      " 1   user_id         107958 non-null  object        \n",
      " 2   created_at      107958 non-null  datetime64[us]\n",
      " 3   order_date      107958 non-null  datetime64[us]\n",
      " 4   user_order_seq  107958 non-null  int64         \n",
      " 5   ordered_items   107958 non-null  object        \n",
      " 6   user_nuts1      107148 non-null  object        \n",
      " 7   variant_id      92361 non-null   float64       \n",
      " 8   price           92361 non-null   float64       \n",
      "dtypes: datetime64[us](2), float64(2), int64(2), object(3)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "orders_nuts = df_orders.merge(df_users[['user_id', 'user_nuts1']], on='user_id', how='left').explode('ordered_items')\n",
    "df_merged = orders_nuts.merge(df_inventory[['variant_id', 'price']], left_on='ordered_items', right_on='variant_id', how='left')\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the merge of the dataframes, we have 15597 null rows at 'variant_id' and 'price', the variables we have joined. We can assume that there are products that were purchased and are no longer in ‘inventory.parquet’ or that they have changed their ‘id’. But we have enough data to test the hypothesis and we will delete these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              count       mean        std    min      25%    50%    75%  \\\n",
      "user_nuts1                                                                \n",
      "UKC          2680.0  62.128377  24.261948   1.99  47.0600  54.16  75.29   \n",
      "UKD          5870.0  56.727482  22.132205   2.98  45.9700  52.55  61.87   \n",
      "UKE          5864.0  61.849615  30.532447   4.79  45.5000  52.62  65.03   \n",
      "UKF          5781.0  57.506585  21.495969   4.76  45.5300  52.28  63.48   \n",
      "UKG          5527.0  58.055602  22.108602   5.58  46.8900  52.71  63.84   \n",
      "UKH         10863.0  66.013245  35.378781   5.28  46.9000  54.44  71.47   \n",
      "UKI         26381.0  66.440882  37.514547   0.99  47.7900  53.23  69.55   \n",
      "UKJ         18159.0  66.439914  35.881358   1.99  47.3000  55.06  73.24   \n",
      "UKK         13926.0  61.172730  27.130163   0.99  46.1200  53.95  66.26   \n",
      "UKL          4848.0  68.303267  35.767825  10.47  50.1925  56.94  72.77   \n",
      "UKM          6749.0  65.129874  37.954970   7.08  46.6500  53.94  70.47   \n",
      "UKN            53.0  53.518679  20.944562   7.38  44.2700  56.26  76.75   \n",
      "\n",
      "               max  \n",
      "user_nuts1          \n",
      "UKC         152.39  \n",
      "UKD         191.88  \n",
      "UKE         200.77  \n",
      "UKF         168.31  \n",
      "UKG         160.15  \n",
      "UKH         221.31  \n",
      "UKI         256.47  \n",
      "UKJ         319.80  \n",
      "UKK         231.33  \n",
      "UKL         271.89  \n",
      "UKM         319.80  \n",
      "UKN          76.75  \n"
     ]
    }
   ],
   "source": [
    "df_merged = df_merged.dropna(subset=['price'])\n",
    "df_total_price = df_merged.groupby('id')['price'].sum().reset_index()\n",
    "nuts_price = df_hyp1.merge(df_total_price, on='id', how='left')\n",
    "\n",
    "summary_nuts_price = nuts_price.groupby('user_nuts1')['price'].describe()\n",
    "print(summary_nuts_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 2:\n",
    "Users segmented as Top-Up should make small purchases with a high frequency and users segmented as Proposition should make large purchases infrequently. (To validate this we will use the 'user_segment' variable from the user dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_hyp2 \u001b[38;5;241m=\u001b[39m df_hyp1\u001b[38;5;241m.\u001b[39mmerge(df_users[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_segment\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m summary_segment_price \u001b[38;5;241m=\u001b[39m \u001b[43mdf_hyp2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_segment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary_segment_price)\n",
      "File \u001b[1;32mc:\\Users\\ALEX\\OneDrive\\Escritorio\\PROGRAMACION\\ZRIVE\\zrive-ds\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1771\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1765\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1768\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1769\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1770\u001b[0m     )\n\u001b[1;32m-> 1771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ALEX\\OneDrive\\Escritorio\\PROGRAMACION\\ZRIVE\\zrive-ds\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: price'"
     ]
    }
   ],
   "source": [
    "df_hyp2 = df_hyp1.merge(df_users[['user_id', 'user_segment']], on='user_id', how='left')\n",
    "\n",
    "summary_segment_price = df_hyp2.groupby('user_segment')['price'].describe()\n",
    "print(summary_segment_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Which products sell the most by geographic area, to see if there is variation in specific products between different areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 92361 entries, 70 to 107957\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id              92361 non-null  int64         \n",
      " 1   user_id         92361 non-null  object        \n",
      " 2   created_at      92361 non-null  datetime64[us]\n",
      " 3   order_date      92361 non-null  datetime64[us]\n",
      " 4   user_order_seq  92361 non-null  int64         \n",
      " 5   ordered_items   92361 non-null  object        \n",
      " 6   user_nuts1      91716 non-null  object        \n",
      " 7   variant_id      92361 non-null  float64       \n",
      " 8   product_type    92361 non-null  object        \n",
      "dtypes: datetime64[us](2), float64(1), int64(2), object(4)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_q1 = df_orders.merge(df_users[['user_id', 'user_nuts1']], on='user_id', how='left') \n",
    "df_q1_expanded = df_q1.explode('ordered_items')\n",
    "df_q1_merged = df_q1_expanded.merge(df_inventory[['variant_id', 'product_type']], left_on='ordered_items', right_on='variant_id', how='left')\n",
    "df_q1_merged = df_q1_merged.dropna(subset=['product_type'])\n",
    "df_q1_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_by_zone  = df_q1_merged.groupby(['user_nuts1', 'product_type']).size().unstack(fill_value=0)\n",
    "relative_products_by_zone = products_by_zone.div(products_by_zone.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_nuts1\n",
      "UKC    [cleaning-products, tins-packaged-foods, toile...\n",
      "UKD    [cleaning-products, tins-packaged-foods, toile...\n",
      "UKE    [cleaning-products, tins-packaged-foods, dishw...\n",
      "UKF    [cleaning-products, tins-packaged-foods, toile...\n",
      "UKG    [cleaning-products, tins-packaged-foods, toile...\n",
      "UKH    [cleaning-products, tins-packaged-foods, toile...\n",
      "UKI    [cleaning-products, tins-packaged-foods, toile...\n",
      "UKJ    [tins-packaged-foods, cleaning-products, long-...\n",
      "UKK    [tins-packaged-foods, long-life-milk-substitut...\n",
      "UKL    [tins-packaged-foods, cleaning-products, long-...\n",
      "UKM    [long-life-milk-substitutes, cleaning-products...\n",
      "UKN    [cleaning-products, delicates-stain-remover, d...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Obtener los 3 productos más comunes por zona\n",
    "top_3_products_per_zone = relative_products_by_zone.apply(lambda row: row.nlargest(3).index.tolist(), axis=1)\n",
    "print(top_3_products_per_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Check if there is a relationship between product_type and cart abandonment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_sold_by_type = df_orders.explode('ordered_items').merge(df_inventory[['variant_id',\n",
    "                                                                               'product_type']], left_on='ordered_items', \n",
    "                                                                 right_on='variant_id', how='left')['product_type'].value_counts().reset_index()\n",
    "products_sold_by_type.columns = ['product_type', 'sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_abandoned_by_type = df_abandoned_carts.explode('variant_id').merge(df_inventory[['variant_id', \n",
    "                                                                     'product_type']], on='variant_id', \n",
    "                                                       how='left')['product_type'].value_counts().reset_index()\n",
    "products_abandoned_by_type.columns = ['product_type', 'abandoned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_vs_abandoned = products_sold_by_type.merge(products_abandoned_by_type, on='product_type', how='left')\n",
    "sold_vs_abandoned['abandonment_rate'] = sold_vs_abandoned['abandoned'] / (sold_vs_abandoned['abandoned'] + sold_vs_abandoned['sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>sold</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>mixed-bundles</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>medicine-treatments</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>household-sundries</td>\n",
       "      <td>146</td>\n",
       "      <td>116</td>\n",
       "      <td>0.442748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>medicines-treatments</td>\n",
       "      <td>97</td>\n",
       "      <td>72</td>\n",
       "      <td>0.426036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>superfoods-supplements</td>\n",
       "      <td>159</td>\n",
       "      <td>107</td>\n",
       "      <td>0.402256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>low-no-alcohol</td>\n",
       "      <td>58</td>\n",
       "      <td>39</td>\n",
       "      <td>0.402062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>spirits-liqueurs</td>\n",
       "      <td>578</td>\n",
       "      <td>350</td>\n",
       "      <td>0.377155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>cider</td>\n",
       "      <td>215</td>\n",
       "      <td>114</td>\n",
       "      <td>0.346505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>washing-capsules</td>\n",
       "      <td>1127</td>\n",
       "      <td>581</td>\n",
       "      <td>0.340164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>maternity</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              product_type  sold  abandoned  abandonment_rate\n",
       "57           mixed-bundles     2          3          0.600000\n",
       "56     medicine-treatments    27         30          0.526316\n",
       "46      household-sundries   146        116          0.442748\n",
       "47    medicines-treatments    97         72          0.426036\n",
       "45  superfoods-supplements   159        107          0.402256\n",
       "50          low-no-alcohol    58         39          0.402062\n",
       "36        spirits-liqueurs   578        350          0.377155\n",
       "43                   cider   215        114          0.346505\n",
       "24        washing-capsules  1127        581          0.340164\n",
       "52               maternity    40         20          0.333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q2.sort_values('abandonment_rate', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>sold</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tea</td>\n",
       "      <td>1232</td>\n",
       "      <td>315</td>\n",
       "      <td>0.203620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>deodorant</td>\n",
       "      <td>299</td>\n",
       "      <td>75</td>\n",
       "      <td>0.200535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>coffee</td>\n",
       "      <td>729</td>\n",
       "      <td>175</td>\n",
       "      <td>0.193584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>baby-toddler-food</td>\n",
       "      <td>484</td>\n",
       "      <td>116</td>\n",
       "      <td>0.193333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cereal</td>\n",
       "      <td>3014</td>\n",
       "      <td>700</td>\n",
       "      <td>0.188476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pet-care</td>\n",
       "      <td>238</td>\n",
       "      <td>52</td>\n",
       "      <td>0.179310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bin-bags</td>\n",
       "      <td>1083</td>\n",
       "      <td>232</td>\n",
       "      <td>0.176426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>adult-incontinence</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long-life-milk-substitutes</td>\n",
       "      <td>6637</td>\n",
       "      <td>1134</td>\n",
       "      <td>0.145927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>baby-milk-formula</td>\n",
       "      <td>787</td>\n",
       "      <td>102</td>\n",
       "      <td>0.114736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_type  sold  abandoned  abandonment_rate\n",
       "21                         tea  1232        315          0.203620\n",
       "40                   deodorant   299         75          0.200535\n",
       "33                      coffee   729        175          0.193584\n",
       "37           baby-toddler-food   484        116          0.193333\n",
       "8                       cereal  3014        700          0.188476\n",
       "42                    pet-care   238         52          0.179310\n",
       "25                    bin-bags  1083        232          0.176426\n",
       "53          adult-incontinence    39          7          0.152174\n",
       "2   long-life-milk-substitutes  6637       1134          0.145927\n",
       "32           baby-milk-formula   787        102          0.114736"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q2.sort_values('abandonment_rate', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "- It confirms the hypothesis that London and South East UK, being the areas with higher income levels, have a higher expenditure on purchases, although there are areas with a similar purchase price that we did not expect, such as Wales.\n",
    "- The hypothesis about user segment is confirmed, as the Top Up consumer makes more purchases than the Proposition consumer, and the Proposition consumer makes purchases with higher spending.\n",
    "\n",
    "- There's no clear reason to say that de area influences on the type of the products are bought. The most sold products are similar in all areas.\n",
    "- The type of product clearly influences the likelihood of it being abandoned in the cart. Products considered more ‘necessary’ or essential, such as baby food or bin bags, have a low abandonment rate, menawhile products that require more consideration, such as medicines, alcoholic drinks, are more likely to be abandoned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
